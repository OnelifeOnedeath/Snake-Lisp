#!/usr/bin/env python3
"""
Snake-Lisp Parser üêç
–ü–∞—Ä—Å–µ—Ä - –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –≤ AST (Abstract Syntax Tree)
"""

class ASTNode:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —É–∑–ª–æ–≤ AST"""
    def __repr__(self):
        return f"{self.__class__.__name__}({self.__dict__})"

class NumberNode(ASTNode):
    def __init__(self, value):
        self.value = float(value) if '.' in str(value) else int(value)

class SymbolNode(ASTNode):
    def __init__(self, name):
        self.name = name

class StringNode(ASTNode):
    def __init__(self, value):
        self.value = value[1:-1]  # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏

class ListNode(ASTNode):
    def __init__(self, elements):
        self.elements = elements
    
    def __repr__(self):
        return f"List({self.elements})"

class Parser:
    """–ü–∞—Ä—Å–µ—Ä Snake-Lisp - –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –≤ AST"""
    
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0
    
    def current_token(self):
        """–¢–µ–∫—É—â–∏–π —Ç–æ–∫–µ–Ω"""
        if self.pos < len(self.tokens):
            return self.tokens[self.pos]
        return None
    
    def eat(self, token_type=None):
        """–°—ä–µ–¥–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ç–æ–∫–µ–Ω –∏ –¥–≤–∏–≥–∞–µ–º—Å—è –¥–∞–ª—å—à–µ"""
        token = self.current_token()
        if not token:
            raise SyntaxError("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞")
        
        if token_type and token.type != token_type:
            raise SyntaxError(f"–û–∂–∏–¥–∞–ª—Å—è {token_type}, –Ω–æ –ø–æ–ª—É—á–µ–Ω {token.type} at {token.line}:{token.column}")
        
        self.pos += 1
        return token
    
    def parse(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        return self.parse_expression()
    
    def parse_expression(self):
        """–ü–∞—Ä—Å–∏–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ"""
        token = self.current_token()
        
        if not token:
            return None
        
        if token.type == 'LPAREN':
            return self.parse_list()
        elif token.type == 'NUMBER':
            return NumberNode(self.eat('NUMBER').value)
        elif token.type == 'STRING':
            return StringNode(self.eat('STRING').value)
        elif token.type == 'SYMBOL':
            return SymbolNode(self.eat('SYMBOL').value)
        else:
            raise SyntaxError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω: {token.type} at {token.line}:{token.column}")
    
    def parse_list(self):
        """–ü–∞—Ä—Å–∏–º —Å–ø–∏—Å–æ–∫ (S-Expression)"""
        self.eat('LPAREN')  # –°—ä–µ–¥–∞–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
        
        elements = []
        while self.current_token() and self.current_token().type != 'RPAREN':
            elements.append(self.parse_expression())
        
        self.eat('RPAREN')  # –°—ä–µ–¥–∞–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
        return ListNode(elements)

# –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä
if __name__ == "__main__":
    from lexer import Lexer
    
    code = """
    (+ 1 2 3)
    (define pi 3.14159)
    "hello world"
    """
    
    # –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    lexer = Lexer(code)
    tokens = lexer.tokenize()
    
    print("=== –¢–û–ö–ï–ù–´ ===")
    for token in tokens:
        print(token)
    
    # –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    parser = Parser(tokens)
    ast = parser.parse()
    
    print("\n=== AST ===")
    print(ast)
